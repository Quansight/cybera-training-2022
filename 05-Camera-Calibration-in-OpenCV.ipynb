{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- OpenCV checkerboard based camera calibration\n",
    "- Image undistortion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chessboards are frequently used as test images for camera calibration in computer vision.\n",
    "+ [Chessboard detection](https://en.wikipedia.org/wiki/Chessboard_detection)\n",
    "+ [OpenCV tutorial on camera calibration](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html)\n",
    "\n",
    "The task here is to use utilities bundled with OpenCV to calibrate a camera from a set of chessboard images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration using a checkerboard pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: loading a sequence of chessboard images\n",
    "\n",
    "The directory `data` contains a set of images `left01.jpg`, `left02.jpg`, ... `left14.jpg` that can be used for camera calibration. Use a glob pattern to create a list `images` of all the image filepaths (i.e., a list of strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02/solution_01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: examining the first image\n",
    "\n",
    "Extract the first image filename from the list `images` and convert it to a grayscale image.\n",
    "+ Use [`cv.imread`](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html?highlight=imread#imread) to load the image.\n",
    "+ Use [`cv.cvtColor`](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor) to convert the image from RGB to grayscale.\n",
    "+ Use the identifier `img` for the original image & `gray` for the grayscale version\n",
    "+ Use `plt.imshow` to visualize the image `gray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02/solution_02.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: examining the first image\n",
    "\n",
    "+ Use the [`findChessboardCorners` function](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#findchessboardcorners) built-in to OpenCV to extract the corners from the image `gray`.\n",
    "    + Assume a pattern of size `(9,6)` (corresponding to the interior corners to locate in the chessboard).\n",
    "    + Assign the output array of corner coordinates to the identifier `corners`.\n",
    "+ Use NumPy's `squeeze` function to eliminate singleton dimensions from the array `corners`.\n",
    "\n",
    "We'll see later how corner detection is actually done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02/solution_03.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the image `img` and the array `corners`, we can now produce a figure showing the original image and the image with circles overlaid on the corner coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = np.copy(img)  # Make a copy of original img as img2\n",
    "\n",
    "# Add circles to img2 at each corner identified\n",
    "for corner in corners:\n",
    "    coord = (corner[0], corner[1])\n",
    "    cv.circle(img=img2, center=coord, radius=5, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "# Produce a figure with the original image img in one subplot and modified image img2 (with the corners added in).\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`cornerSubPix` function](https://docs.opencv.org/2.4/modules/imgproc/doc/feature_detection.html#cornersubpix) from OpenCV can be used to refine the corners extracted to sub-pixel accuracy. This is based on an iterative technique; as such, one of the inputs `criteria` uses a tuple to bundle a convergence tolerance and a maximum number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001) # Set termination criteria as a tuple.\n",
    "corners_orig = corners.copy()  # Preserve the original corners for comparison after\n",
    "corners = cv.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria=criteria) # extract refined corner coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine how much the corners have shifted (in pixels)\n",
    "shift = corners - corners_orig\n",
    "print(shift[:4,:])\n",
    "print(np.linalg.norm(shift.reshape(-1,1), np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate a figure to compare the original corners to the corrected corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = np.copy(img)\n",
    "\n",
    "for corner in corners:\n",
    "    coord = (corner[0], corner[1])\n",
    "    cv.circle(img=img3, center=coord, radius=5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(211)\n",
    "plt.imshow(img2[200:300,200:400,:])\n",
    "plt.subplot(212)\n",
    "plt.imshow(img3[200:300,200:400,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [`drawChessboardCorners`](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#drawchessboardcorners) generates a new image with circles at the corners detected. The corners are displayed either as red circles if the board was not found, or as colored corners connected with lines if the board was found (as determined by the output argument `retval` from `findChessboardCorners`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = cv.drawChessboardCorners(img, (9, 6), corners, retval)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to repeat this process with all the chessboard images to remove distortion effects. First, assume a 3d world coordinate system aligned with the chessboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_grid = np.zeros((9*6,3), np.float32)\n",
    "obj_grid[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "print(obj_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize enpty list to accumulate coordinates\n",
    "obj_points = [] # 3d world coordinates\n",
    "img_points = [] # 2d image coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "for fname in images:\n",
    "    print('Loading {}'.format(fname))\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    retval, corners = cv.findChessboardCorners(gray, (9,6))\n",
    "    if retval:\n",
    "        obj_points.append(obj_grid)        \n",
    "        corners2 = cv.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        img_points.append(corners2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accumulated lists of object coordinates and image coordinates can be combined to determine an optimal set of camera calibration parameters. The relevant OpenCV utility here is [`calibrateCamera`](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.calibrateCamera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, mtx, dist, rvecs, tvecs = cv.calibrateCamera(obj_points, img_points, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retval) # Objective function value\n",
    "print(mtx)    # Camera matrix\n",
    "print(dist)   # Distortion coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [`getOptimalNewCameraMatrix`](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.getOptimalNewCameraMatrix) can use the optimized matrix and distortion coefficients to construct a new camera matrix appropriate for a given image. This can be used to remove distortion effects with [`undistort`](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#undistort)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('data/left12.jpg')\n",
    "h,w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.imshow(dst)\n",
    "plt.title('Corrected');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Based on materials from Prof. Faisal Qureshi (Faculty of Science, Ontario Tech University, Oshawa ON, Canada, http://vclab.science.ontariotechu.ca)\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
