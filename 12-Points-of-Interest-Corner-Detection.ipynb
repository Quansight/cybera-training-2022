{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points of Interest: Corner Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Outline\n",
    "\n",
    "- Characteristics of good features\n",
    "- Corner detection\n",
    "- Harris corner detector\n",
    "- OpenCV Harris corner detection\n",
    "\n",
    "*This notebook focuses on interest point detection.  We leave feature descriptors and feature matching for an other time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Detecting points of interest (e.g., corners) is very useful for:\n",
    "- Image alignment\n",
    "- 3D reconstruction\n",
    "- Tracking\n",
    "- Object recognition\n",
    "- Image retrieval\n",
    "- Navigation (or mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Example: Image (or object) matching\n",
    "\n",
    "Step 1: Detect interest points locations\n",
    "\n",
    "Step 2: Compute feature descriptors around interest point locations\n",
    "\n",
    "Step 3: Use descriptor matching for finding corresponding locations in two or more images\n",
    "\n",
    "**Detection**\n",
    "\n",
    "Identify interest point locations\n",
    "\n",
    "**Description**\n",
    "\n",
    "Extract *features* around interest point locations.  These features describe (or capture) the local appearance characteristics around these locations.\n",
    "\n",
    "**Matching**\n",
    "\n",
    "Match features between two or more images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Characteristics of Good Features\n",
    "\n",
    "- *Repeatability* — feature is invariant to geometric, lighting, etc. changes \n",
    "- *Saliency* or distinctiveness - Invariance to geometric and photometric differences between two images\n",
    "- *Compactness* — efficiency, many fewer features than the number of pixels in the image\n",
    "- *Locality* — robustness to clutter and occlusion, a feature should only occupy a small area of an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Detecting Interest Point Locations\n",
    "\n",
    "Which is a better location for an interest point: A or B?\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/interest-points.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Courtesy K. Grauman</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Intuition\n",
    "\n",
    "We should easily recognize the point looking through a small window\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/interest-points-window.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Courtesy K. Grauman</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Corner Detection\n",
    "\n",
    "In the following figure: (left) represents a flat region where there is no change is observed in any direction as we move the window; (middle) represents an edge region where change is observed in one direction only as we move the window; and (right) represents a corner region where change is observed in two direction as we move the window.  \n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/corner-detection.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Courtesy K. Grauman</figcaption>\n",
    "</figure>\n",
    "\n",
    "Notice that unlike flat and edge regions, corners can be \"easily\" localized.  Recall that this is one of the requirements for interest point detection.\n",
    "\n",
    "In the remaining of this section, we will focus on corner detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Quantifying neighbourhood structure\n",
    "\n",
    "We can capture the change in appearance as we move the window around as follows:\n",
    "\n",
    "$$\n",
    "E(u,v) = \\sum_{x,y} w(x,y) [I(x+u, y+v) - I(x,y)]^2\n",
    "$$\n",
    "\n",
    "Here $w(x,y)$ is a some suitable weighting function. $I(x,y)$ represent the intensity of the image at location $(x,y)$ and $I(x+u, y+v)$ represents the intensity of image at shifted location $(x+u, y+v)$.  $E(u,v)$ is often computed on a small region centered around $(x,y)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_rect(cx, cy, w, h, color='red', width=4):\n",
    "    \"\"\"\n",
    "    Requires `import matplotlib as mpl`\n",
    "    \"\"\"\n",
    "    ax = plt.gca()\n",
    "\n",
    "    t, b = cy-h//2, cy+h//2\n",
    "    l, r = cx-w//2, cx+w//2\n",
    "       \n",
    "    rect = mpl.lines.Line2D([l,l,r,r,l],[t,b,b,t,t],color=color,linewidth=width)\n",
    "    ax.add_line(rect)\n",
    "    return int(t), int(b), int(l), int(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Consider the following windows sitting at location $(12,12)$.  Lets shift it by some value $(u,v)$ and compute $E(u,v)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "I = 0.4*np.ones((25,25)) # Flat\n",
    "I[12:,12:] += 0.6 #np.ones((13,13))*0.5+0.6 # Corner\n",
    "#I[:,12:] = np.ones((25,13))*0.5+0.6 # Line\n",
    "I += 0.1*np.random.rand(25,25)\n",
    "\n",
    "cx, cy, w, h = 12, 12, 12, 12\n",
    "u, v = -0, +4\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Input image')\n",
    "plt.imshow(I, interpolation='none', cmap='gray')\n",
    "t, b, l, r = draw_rect(cx, cy, w, h)\n",
    "plt.plot([cx],[cx],'r*')\n",
    "t_shifted, b_shifted, l_shifted, r_shifted = draw_rect(cx+u, cy+v, w, h, color='green')\n",
    "plt.plot([cx+u],[cy+v],'g*')\n",
    "plt.subplot(132)\n",
    "plt.title('Region centered at ({},{})'.format(cx,cy))\n",
    "I_region = I[t:b,l:r]\n",
    "plt.imshow(I_region, interpolation='none', cmap='gray')\n",
    "plt.subplot(133)\n",
    "plt.title('Shifted region')\n",
    "I_shifted = I[t_shifted:b_shifted,l_shifted:r_shifted]\n",
    "plt.imshow(I_shifted, interpolation='none', cmap='gray')\n",
    "E = np.sum(np.square(I_region - I_shifted)) # Assume w(x,y)=1.0\n",
    "print('E({},{}) = {}'.format(u,v,E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "E = np.zeros((13,13), dtype=np.float32)\n",
    "for u in np.arange(-6,7):\n",
    "    for v in np.arange(-6,7):\n",
    "        t, b = int(cy-h//2), int(cy+h//2)\n",
    "        l, r = int(cx-w//2), int(cx+w//2)\n",
    "        ts, bs, ls, rs = t+v, b+v, l+u, r+u   \n",
    "        E[u+6,v+6] = np.sum(np.square(I[t:b,l:r] - I[ts:bs,ls:rs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.title('$E(u,v)$')\n",
    "plt.imshow(E, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(projection='3d')\n",
    "X = np.arange(0,13)\n",
    "Y = np.arange(0,13)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = E\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Analyzing *E(u,v)*\n",
    "\n",
    "The shape of $E(u,v)$ tells us about the underlying image structure: flat region, edge region, or corner region. Lets try to figure out how $E(u,v)$ behaves for small shifts $(u,v)$.  We can use Taylor Series to approximate $E$ around $(u,v)$. \n",
    "\n",
    "$$\n",
    "E(u,v) = E(0,0) + \n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "u & v\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "E_u(0,0) \\\\ E_v(0,0)\n",
    "\\end{array}\n",
    "\\right] +\n",
    "\\frac{1}{2}\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "u & v\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "E_{uu}(0,0) & E_{uv}(0,0) \\\\ E_{uv}(0,0) & E_{vv}(0,0)\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "u \\\\ v\n",
    "\\end{array}\n",
    "\\right]\n",
    "+\n",
    "\\cdots\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Lets do some maths\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E_u(u,v) & = \\sum_{x,y} 2 w(x,y) \\left[ I(x+u,y+v)-I(x,y)  \\right] I_x(x+u,y+v) \\\\\n",
    "E_{uu}(u,v) & = \\sum_{x,y} 2 w(x,y) I_x(x+u,y+v) I_x(x+u,y+v) + \\sum_{x,y} 2 w(x,y) \\left[ I(x+u,y+v)-I(x,y)  \\right] I_{xx}(x+u,y+v) \\\\\n",
    "E_{uv}(u,v) & = \\sum_{x,y} 2 w(x,y) I_y(x+u,y+v) I_x(x+u,y+v) + \\sum_{x,y} 2 w(x,y) \\left[ I(x+u,y+v)-I(x,y)  \\right] I_{xy}(x+u,y+v) \\\\\n",
    "E_{vv}(u,v) & = \\sum_{x,y} 2 w(x,y) I_y(x+u,y+v) I_y(x+u,y+v) + \\sum_{x,y} 2 w(x,y) \\left[ I(x+u,y+v)-I(x,y)  \\right] I_{yy}(x+u,y+v)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Evaluating the derivatives above at $(u,v)=(0,0)$ gives the coefficients in the preceding Taylor Series:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(0,0) & = 0 \\\\\n",
    "E_u(0,0) & = 0 \\\\\n",
    "E_v(0,0) & = 0 \\\\\n",
    "E_{uu}(0,0) & = \\sum_{x,y} 2 w(x,y) I_x(x,y) I_x(x,y) \\\\\n",
    "E_{vv}(0,0) & = \\sum_{x,y} 2 w(x,y) I_y(x,y) I_y(x,y) \\\\\n",
    "E_{uv}(0,0) & = \\sum_{x,y} 2 w(x,y) I_x(x,y) I_y(x,y)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "This means that\n",
    "$$\n",
    "\\begin{align}\n",
    "E(u,v) & \\approx \\frac{1}{2}\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "u & v\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "\\sum_{x,y} 2 w(x,y) I_x(x,y) I_x(x,y) & \\sum_{x,y} 2 w(x,y) I_x(x,y) I_y(x,y) \\\\ \\sum_{x,y} 2 w(x,y) I_x(x,y) I_y(x,y) & \\sum_{x,y} 2 w(x,y) I_y(x,y) I_y(x,y)\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "u \\\\ v\n",
    "\\end{array}\n",
    "\\right] \\\\\n",
    "& = \\sum_{x,y} w(x,y) \\left[\n",
    "\\begin{array}{cc}\n",
    "u & v\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "I_x^2 & I_x I_y \\\\ I_x I_y & I_y^2\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "u \\\\ v\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{align}, \n",
    "$$\n",
    "that is, $E(u,v)$ is approximately a homogeneous quadratic form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "With this exercise, we get the second moment matrix \n",
    "\n",
    "$$\n",
    "M = \\sum_{x,y} w(x,y)  \\left[\n",
    "\\begin{array}{cc}\n",
    "I_x^2 & I_x I_y \\\\ I_x I_y & I_y^2\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "which captures the local changes in the image around location $(x,y)$.  We can use $M$ to identify if $(x,y)$ is sitting on a corner.  Note also that matrix $M$ can be computed from image derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Local surface approximation\n",
    "\n",
    "The surface $E(u,v)$ is locally approximated by a quadratic form.\n",
    "\n",
    "$$\n",
    "E(u,v) \\approx \\left[\n",
    "\\begin{array}{cc}\n",
    "u & v\n",
    "\\end{array}\n",
    "\\right]\n",
    "M\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "u \\\\ v\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "M = \\sum_{x,y} w(x,y) \\left[\n",
    "\\begin{array}{cc}\n",
    "I_x^2 & I_x I_y \\\\ I_x I_y & I_y^2\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "<center>\n",
    "<tr>\n",
    "    <td><img src=\"images/corner-surface-approx.png\" width=\"50%\"></img></td>\n",
    "</tr>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<tr>\n",
    "    <td><img src=\"images/corner-surface-approx-2.png\" width=\"50%\"></img></td>\n",
    "</tr>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Second Moment Matrix Interpretation\n",
    "\n",
    "Lets first consider the axis aligned case where\n",
    "\n",
    "$$\n",
    "M = \\left[ \n",
    "\\begin{array}{cc} \n",
    "\\lambda_1 & 0 \\\\ \n",
    "0 & \\lambda_2 \n",
    "\\end{array}  \n",
    "\\right]\n",
    "$$\n",
    "\n",
    "If both $\\lambda_1$ and $\\lambda_2$ are close to zero, it means that there is no change along either directions (i.e., flat region).  If either $\\lambda_1$ or $\\lambda_2$ are zero then it means that the change is only along one direction (i.e., edge region).  If neither $\\lambda_1$ or $\\lambda_2$ are zero, it means that there is change in both directions (i.e., corner region).\n",
    "\n",
    "We use this intuition and diagonalize matrix\n",
    "\n",
    "$$\n",
    "M = \\sum_{x,y} w(x,y)  \\left[\n",
    "\\begin{array}{cc}\n",
    "I_x^2 & I_x I_y \\\\ I_x I_y & I_y^2\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "This is accomplished by computing its eigenvectors and eigenvalues.  Here eigenvectors represent the two directions, and eigenvalues represent change along these directions.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/corners-ellipse.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Courtesy K. Grauman</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/corners-visualization.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Courtesy K. Grauman</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Classifying Image Pixels\n",
    "\n",
    "- Pixel is sitting in a **flat region**: $\\lambda_1$ and $\\lambda_2$ are small.  $E$ is almost constant in all directions.\n",
    "\n",
    "- Pixel is sitting on an **edge**: $\\lambda_1 \\gg \\lambda_2$ or $\\lambda_2 \\gg \\lambda_1$.  $E$ remains almost constant in one direction.\n",
    "\n",
    "- Pixel is sitting on a **corner**: $\\lambda_1$ and $\\lambda_2$ are large.  $\\lambda_1 \\backsim \\lambda_2$.  $E$ increases in all directions.\n",
    "\n",
    "The following corner response function formalizes these notions.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "R & = \\mathrm{det}(M) - \\alpha\\ \\mathrm{trace}(M)^2 \\\\\n",
    "& = \\lambda_1 \\lambda_2 - \\alpha (\\lambda_1 + \\lambda_2)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here $\\alpha$ is a constant.  Typical values for $\\alpha$ varies between $0.4$ and $0.6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Example\n",
    "\n",
    "Consider the following code, that generates a 16-by-16 image.  Compute 2-by-2 second moment matrix for location $(7,7)$, which is indicated as the red dot on the figure below.  For this discussion, we assume that we use a window of size 5-by-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "I = np.ones((16,16), dtype='float')\n",
    "I[:8,:8] = np.zeros((8,8))\n",
    "plt.imshow(I, cmap='gray')\n",
    "plt.plot(7,7,'ro');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute derivatives using OpenCV Sobel operator\n",
    "Ix = cv.Sobel(I, cv.CV_64F, 1, 0, ksize=5)\n",
    "Iy = cv.Sobel(I, cv.CV_64F, 0, 1, ksize=5)\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1)\n",
    "ax[0].imshow(Ix, cmap='gray')\n",
    "ax[0].set_title('$I_x$')\n",
    "ax[1].imshow(Iy, cmap='gray')\n",
    "ax[1].set_title('$I_y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ix2 = np.multiply(Ix,Ix)\n",
    "Iy2 = np.multiply(Iy,Iy)\n",
    "IxIy = np.multiply(Ix,Iy)\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1)\n",
    "ax[0].imshow(Ix2, cmap='gray')\n",
    "ax[0].set_title('$I_{x}^2$')\n",
    "ax[1].imshow(Iy2, cmap='gray')\n",
    "ax[1].set_title('$I_{y}^2$')\n",
    "ax[2].imshow(IxIy, cmap='gray')\n",
    "ax[2].set_title('$I_{x}I_{y}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIx2 = cv.blur(Ix2, (5,5)).flatten()\n",
    "SIy2 = cv.blur(Iy2, (5,5)).flatten()\n",
    "SIxIy = cv.blur(IxIy, (5,5)).flatten()\n",
    "\n",
    "M = np.vstack((SIx2, SIxIy, SIxIy, SIy2 )).reshape(4,16,16)\n",
    "print('M at (7,7) =\\n', M[:,7,7].reshape(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Harris Corner Detector\n",
    "\n",
    "[Harris and Stephens, 1988]\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-1.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>\n",
    "\n",
    "1. Compute $M$ matrix for each image window to get their cornerness scores.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-2.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>\n",
    "\n",
    "2. Find points whose surrounding window gave large corner response.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-3.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>\n",
    "\n",
    "3. Take the points of local maxima, i.e., perform non-maximum suppression.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-4.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-5.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Invariance and Covariance\n",
    "\n",
    "We want corner locations to be invariant to photometric transformations and covariant to geometric transformations\n",
    "\n",
    "- Invariance: image is transformed and corner locations do not change\n",
    "\n",
    "- Covariance: if we have two transformed versions of the same image, features should be detected in corresponding locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Affine Intensity Change\n",
    "\n",
    "- Corner response is partially invariant to affine intensity change\n",
    "\n",
    "Say $I$ and $I_\\mathrm{new}$ is the current and \"new\" instensity of a pixel then\n",
    "\n",
    "$$\n",
    "I_\\mathrm{new} = a I + b\n",
    "$$\n",
    "\n",
    "Notice that corner response function uses derivatives only.  This suggests that it is \"invariant\" to change from $I$ to $I_\\mathrm{new}$.  However, in order to find corner locations, we need to threshold on corner response.  This suggests corner response is **not** invariant to changes in intensity.  \n",
    "\n",
    "Specifically, corner response is invariant to intensity shift $I \\to I + b$; however, corner response is not invariant to intensity scaling $I \\to aI$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Image translation and rotation\n",
    "\n",
    "- Corner location is covariant with respect to translation. Derivatives and window function are shift-invariant.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-translation.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>\n",
    "\n",
    "- Corner location is convariant with respect to rotation.  Second moment ellipse rotates, but its shape (i.e., eigenvalues) remains the same.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-rotation.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Image scaling\n",
    "\n",
    "- Corner location is **not** covariant to scaling\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-scaling.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>\n",
    "\n",
    "Use multi-scale analysis for automatic scale selection for corner detection\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/harris-scale-selection.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## OpenCV Harris Corner Detection\n",
    "\n",
    "OpenCV includes a function `cornerHarris` to find corners in an image. We will use this built-in method to confirm our understanding of the limits of corner detection:\n",
    "\n",
    "- covariance to translation and rotation;\n",
    "- partial invariance to shifts in intensity; and\n",
    "- the need for multiscale analysis to achieve scale invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'data/corners-multiscale.png'\n",
    "img = cv.imread(filename) \n",
    "img = cv.resize(img, (256,256))\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(gray, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "We will use OpenCV method `cornerHarris` to perform corner detection on this image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "level = 0\n",
    "dst = cv.cornerHarris(gray, 2, 3, 0.04)\n",
    "dst = cv.dilate(dst, None)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle('Level = {}'.format(level))\n",
    "plt.subplot(121)\n",
    "plt.title('Image')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.title('Harris corner response')\n",
    "plt.imshow(dst, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Notice that corners for three smaller squares are detected.  Notice also that corner detection is *covariant* with respect to translation and rotation.  Corner response varies with changes in intensity; however, it is somewhat robust to changes in intensity.\n",
    "\n",
    "Note also that `cornerHarris` method is unable to find corners of rounded rectangles.  At this scale these corners appear as edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Multiscale analysis for corner detection\n",
    "\n",
    "We need multiscale analysis to also pick corners of the rounded rectangles.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_ = np.copy(gray)\n",
    "level = 0\n",
    "for i in range(6):\n",
    "    level = level + 1\n",
    "    gray_ = cv.pyrDown(gray_)\n",
    "    dst = cv.cornerHarris(gray_, 2, 3, 0.04)\n",
    "    dst = cv.dilate(dst, None)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.suptitle('Level = {}'.format(level))\n",
    "    plt.subplot(121)\n",
    "    plt.title('Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(gray_, cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.title('Harris corner response')\n",
    "    plt.imshow(dst, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Corner detection implementation\n",
    "\n",
    "Below is an implementation of corner detection that follows the \"mathematical\" steps that we have discussed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Step 1 - Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_bgr = cv.imread('data/corner-test.jpg')\n",
    "img = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Step 2 - Compute image derivatives\n",
    "\n",
    "Compute $I_x$ and $I_y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "Ix = cv.Sobel(img_gray, cv.CV_64F, 1, 0, ksize=5)\n",
    "Iy = cv.Sobel(img_gray, cv.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Ix')\n",
    "plt.imshow(Ix, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Iy')\n",
    "plt.imshow(Iy, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Step 3 - 2-by-2 moment matrix\n",
    "\n",
    "Compute $I_x^2$, $I_y^2$, and $I_x I_y$ as needed for the $2$-by-$2$ moment matrices. In the next step, we choose 5-by-5 neighbourhoods around each pixel to compute its moment matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ix2 = np.multiply(Ix,Ix)\n",
    "Iy2 = np.multiply(Iy,Iy)\n",
    "IxIy = np.multiply(Ix,Iy)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('$I_x^2$')\n",
    "plt.imshow(Ix2, cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('$I_y^2$')\n",
    "plt.imshow(Iy2, cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('$I_xI_y$')\n",
    "plt.imshow(IxIy, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIx2 = cv.blur(Ix2, (5,5))\n",
    "SIy2 = cv.blur(Iy2, (5,5))\n",
    "SIxIy = cv.blur(IxIy, (5,5))\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('$\\sum w I_x^2$')\n",
    "plt.imshow(SIx2, cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('$\\sum w I_y^2$')\n",
    "plt.imshow(SIy2, cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('$\\sum w I_xI_y$')\n",
    "plt.imshow(SIxIy, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Step 4 - use moment matrix eigenvalues to compute corner response\n",
    "\n",
    "Use eigenvalues of the moment matrix to compute corner response at each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_corners(SIx2, SIy2, SIxIy):\n",
    "    corners = []\n",
    "    alpha = 0.04\n",
    "    response = np.zeros(SIx2.shape, dtype='float32')\n",
    "    for (x,y),_ in np.ndenumerate(SIx2):\n",
    "        M = np.array([[SIx2[x,y], SIxIy[x,y]], [SIxIy[x,y], SIy2[x,y]]])\n",
    "        w, _ = np.linalg.eig(M)\n",
    "        response[x,y] = w[0]*w[1] - alpha*(w[0]+w[1])*(w[0]+w[1])\n",
    "    return response\n",
    "\n",
    "response = find_corners(SIx2, SIy2, SIxIy)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(response,cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Based on materials from Prof. Faisal Qureshi (Faculty of Science, Ontario Tech University, Oshawa ON, Canada, http://vclab.science.ontariotechu.ca)\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filesystem-cybera",
   "language": "python",
   "name": "conda-env-filesystem-cybera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
