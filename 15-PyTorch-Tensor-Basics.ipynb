{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Why PyTorch Tensors?\n",
    "\n",
    "\n",
    "- [PyTorch](https://pytorch.org): Python-based scientific computing package offering:\n",
    "  - Tensor support (replacement for NumPy)\n",
    "  - Fast & flexible platform for deep learning research\n",
    "+ [What is PyTorch?](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)  at [`pytorch.org`](https://pytorch.org) provides quick tour principal topics (e.g., tensor indexing, arithmetic operations, elementwise functions, linear algebra, etc.)\n",
    "+ Ostensibly similar functionality/API to NumPy; why bother?\n",
    "\n",
    "1. **GPU computation**:\n",
    "  + GPUs (graphical processing units) widely available but challenging to program\n",
    "  + PyTorch eases GPU programming burden with Python interface\n",
    "2. **Automatic differentiation**: \n",
    "  + PyTorch includes [`autograd`](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html) for *backpropagation*\n",
    "  + Management of gradients (and associated memory) simplified with PyTorch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "##  Quick Tour of Torch tensors\n",
    "\n",
    "+ Principal PyTorch data structure: *tensor*\n",
    "+ Similar to NumPy `ndarray` with:\n",
    "\n",
    "    + support for GPU computing\n",
    "    + support for automatic differentiation (see `autograd`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(t.permute(-1,0)) # More general \"transpose\" in higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('shape:',t.shape)\n",
    "print('size:',t.size())\n",
    "print('dim:',t.dim())\n",
    "print('type:',t.type())\n",
    "print('num elements:', torch.numel(t))\n",
    "print('device (cpu or gpu):', t.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ As with NumPy, variety of PyTorch data types for arrays:\n",
    "\n",
    "|  NumPy dtype | PyTorch dtype | Alternative | Tensor class |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| `np.int16`  |`torch.Int16`  |`torch.short` |`ShortTensor` |\n",
    "| `np.int32`  |`torch.Int32`  |`torch.Int`   |`IntTensor`   |\n",
    "| `np.int64`  |`torch.Int64`  |`torch.long`  |`LongTensor`  |\n",
    "| `np.float16`|`torch.float16`|`torch.half`  |`HalfTensor`  |\n",
    "| `np.float32`|`torch.float32`|`torch.float` |`FloatTensor` |\n",
    "| `np.float64`|`torch.float64`|`torch.double`|`DoubleTensor`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Changing tensor views\n",
    "\n",
    "+ Generalization of reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(t)\n",
    "print('View example:\\n', t.view(1,-1))\n",
    "print('View example:\\n', t.view(-1,1))\n",
    "print('View example:\\n', t.view(3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "First row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Matlab or numpy style slicing:\\n',t[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Matlab or numpy style slicing:\\n',t[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Lower right most element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Matlab or numpy style slicing:\\n',t[-1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Lower right most 1 x 1 submatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Matlab or numpy style slicing:\\n',t[-1:,-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Lower right most 2 x 2submatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Matlab or numpy style slicing:\\n',t[-2:,-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Torch tensors and Numpy arrays\n",
    "\n",
    "+ Construction of PyTorch tensors from NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.randn(2, 4)\n",
    "t = torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Back to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('numpy:\\n', a)\n",
    "print('torch:\\n', t)\n",
    "print(type(a))\n",
    "print(type(t))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Creating PyTorch tensors\n",
    "\n",
    "+ Many PyTorch functions/methods similar names to NumPy (e.g., `zeros`, `ones`, `rand`, `randn`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Zero tensor:\\n', torch.zeros(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Ones tensor:\\n', torch.ones(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Random - Uniform, between 0 and 1):\\n', torch.rand(2,3,4))\n",
    "print('Random - Normal, mean 0 and standard deviation 1 :\\n', torch.randn(2,3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Tensor concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1,2,3],[4,5,7]])\n",
    "t2 = torch.tensor([[8,9,10],[11,12,13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('t1:\\n', t1)\n",
    "print('t2:\\n', t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Concatenating two tensors along 0 (first, rows in this case) dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cat((t1,t2),0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Concatenating two tensors along 1 (second, columns in this case) dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cat((t1,t2),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Computing cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(t)\n",
    "print('Sum along columns:\\n', t.cumsum(-1))\n",
    "print('Sum along rows:\\n', t.cumsum(-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### \"Unsqueezing\" tensors (i.e., adding dimensions)\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/tensor-concatination.png\" width=\"50%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ First, NumPy way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(3,4)\n",
    "print('Before', x.shape)\n",
    "x = x.reshape(3,1,4)\n",
    "#x = x[:,np.newaxis,:]   # Equivalent to reshaping\n",
    "#x = x[:,None,:]         # Equivalent to reshaping\n",
    "print('After', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Next, PyTorch way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t = torch.rand(3,4)\n",
    "print('Before:', t.shape)\n",
    "t1 = t.unsqueeze(1) # Inserts singleton dimension in position 1\n",
    "print('After:', t1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Let's consider another $3\\times4$ matrix (e.g., grayscale image or frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t2 = torch.rand(3,4)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Say we want to combine `t1` and `t2` as successive *frames* in first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(t, t.size())\n",
    "t.unsqueeze_(0) # inplace unsqueeze, we just added a dimension\n",
    "print(t, t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(t2, t2.size())\n",
    "t2.unsqueeze_(0)\n",
    "print(t2, t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t_and_t2 = torch.cat((t,t2),0) # concatenates in first dimension\n",
    "print('First dimension iterators over frames:\\n', t_and_t2.shape)\n",
    "print(t_and_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Other operations\n",
    "\n",
    "+ Testing for equality\n",
    "+ \"Vectorized\" functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "t2 = torch.tensor([[1,20,3],[40,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Elementwise equality test (inadvisable with floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(torch.eq(t1,t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t = torch.rand(2,3)\n",
    "print('t:\\n', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('log t:\\n', torch.log(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('neg t:\\n', torch.neg(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('power t:\\n', torch.pow(t, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('reciprocal t:\\n', torch.reciprocal(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('round t:\\n', torch.round(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('sigmoid t:\\n', torch.sigmoid(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('sign t:\\n', torch.sign(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('sqrt t:\\n', torch.sqrt(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "argmax, along 0-th dimension (that moves along the rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('argmax t:\\n', torch.argmax(t, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "mean, along 1-th dimension (that moves along the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('mean t:\\n', torch.mean(t, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Vector & Matrix products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t1 = torch.tensor([0,1,0])\n",
    "t2 = torch.tensor([1,0,0])\n",
    "print(t1.cross(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t1 = torch.randn(4,3)\n",
    "t2 = torch.randn(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Row-wise vector cross product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t1_cross_t2 = t1.cross(t2)\n",
    "print(t1_cross_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Confirm respective cross products are orthogonal to corresponding rows of `t1` and `t2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(t1.size(0)):\n",
    "    print('Row %d' % i, t1[i,:].dot(t1_cross_t2[i,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Matrix multiplication through `torch.tensor.mm` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "m1 = torch.randn(4,3)\n",
    "m2 = torch.randn(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('m1:\\n', m1)\n",
    "print('m2:\\n', m2)\n",
    "# Matrix multiplication\n",
    "print('Matrix multiplication:\\n', m1.mm(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "m1 = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "m2 = torch.tensor([[2,4],[-1,6]], dtype=torch.float32)\n",
    "print('m1:\\n', m1)\n",
    "print('m2:\\n', m2)\n",
    "# Element-wise multiplication (\"Hadamard product\")\n",
    "print('Element-wise multiplication:\\n', m1.mul(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## CUDA GPU Support\n",
    "\n",
    "+ Checking if CUDA GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = torch.cuda.is_available()\n",
    "print('CUDA available (T/F):', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+  How many CUDA devices are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result = torch.cuda.device_count()\n",
    "print('Number of CUDA devices available:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+  PyTorch tensors have `device` attribute; can be set according to availability of GPU hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = torch.ones(10)\n",
    "print(f'a.device: {a.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Timing tensor computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = torch.ones((300000))\n",
    "print(f'a.device: {a.device}')\n",
    "start_time = time.time()\n",
    "print(a.sum().item())\n",
    "end_time = time.time()\n",
    "print('It took {} seconds'.format(end_time - start_time))\n",
    "print('a is sitting on', a.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if not is_cuda:\n",
    "    print('Nothing to do here')\n",
    "else:\n",
    "    a_ = a.cuda()\n",
    "    print(f'a.device: {a.device}')\n",
    "    start_time = time.time()\n",
    "    print(a_.sum())\n",
    "    end_time = time.time()\n",
    "    print('It took {} seconds'.format(end_time - start_time))\n",
    "    print('a is sitting on', a_.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Working with Images\n",
    "\n",
    "+ Load an image usng PIL library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "filename = 'images/3063.jpg'\n",
    "image = Image.open(filename)\n",
    "print(image) # Loaded into suitable Image object with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Converting PIL image to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image_np = np.array(image, dtype='float32')/255.\n",
    "print(image_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Converting NumPy array to PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_tensor = torch.tensor(image_np)\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Displaying image using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.title('PIL image')\n",
    "plt.imshow(image)\n",
    "plt.subplot(132)\n",
    "plt.title('Numpy array')\n",
    "plt.imshow(image_np)\n",
    "plt.subplot(133)\n",
    "plt.title('Torch tensor')\n",
    "plt.imshow(image_tensor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Computing mean and variance of red, blue and green channels\n",
    "  + First, convert  `(w x h x 3)` image to `(3 x w x h)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Shape of image_tensor', image_tensor.shape)\n",
    "x = image_tensor.transpose(0,2).transpose(1,2)\n",
    "print('Shape of x', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "npixels = x.size(1) * x.size(2)\n",
    "print(f'Number of pixels = {npixels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sums = torch.sum(x, dim=(1,2))\n",
    "print('Sum of pixel intensities', sums)\n",
    "print(f'Shape of sum {sums.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "means = sums.view(3,-1) / npixels\n",
    "print('Mean of pixel intensities', means)\n",
    "print(f'Shape of means {means.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_tensor.mean(dim=(0,1)) # Same computation using mean method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x_centered = (x.view(3,-1) - means).view(x.shape)\n",
    "print(x_centered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y = x_centered.transpose(0,2).transpose(0,1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(y)\n",
    "print(torch.min(y))\n",
    "print(torch.max(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Backpropagation with `autograd`\n",
    "\n",
    "+ [`autograd`](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html) module supports *automatic differentiation*\n",
    "+ Remember, gradients needed to train neural network parameters (weights & biases) with (stochastic) gradient descent\n",
    "+ In PyTorch, automatic differentiation uses tensor `requires_grad` attribute\n",
    "  + `torch.Tensor.requires_grad` can be set `True` on construction (default `False`)\n",
    "  + Alternatively, method `torch.Tensor.requires_grad_( ... )` modifies tensor flag in-place (default `False`).\n",
    "\n",
    "+ Once tensors have `requires_grad` attribute, additional space allocated for intermediate computations\n",
    "+ Calling `torch.Tensor.backward()` computes all gradients recursively by backpropagation\n",
    "+ Intermediate gradients accessible using `torch.Tensor.grad` attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Backpropagation example\n",
    "\n",
    "+ Consider simple polynomial function applied to scalar value $x$:\n",
    "\n",
    "$\\begin{aligned} &\\mathrm{Function:} & f(x) &= 3x^4 -2x^3 + 4x^2 - x + 5 \\\\\n",
    "&\\mathrm{Derivative:} & f'(x) &= 12x^3 -6 x^2 + 8x -1\\end{aligned}$\n",
    "\n",
    "1. Construct tensor `x` setting attribute `requires_grad=True` using constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "2. Map polynomial function $f$ onto tensor `x` ; bind result to `y`\n",
    "  + Verify explicitly $f(x)=51$ when $x=2$:\n",
    " $$f(2)=3(2)^4 - 2(2)^3 + 4(2)^2 -(2) +5 = 48-16+16-2+5 = 51$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y = 3*x**4 - 2*x**3 + 4*x**2 - x + 5  # Write out computation of y explicitly.\n",
    "\n",
    "print(f'Value of y: {y}') # Notice y has a new attribute: grad_fn\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Object `y` has associated gradient function accessible `y.grad_fn`\n",
    "+ When `y` computed/stored, various algebraic operations are applied to tensor `x`\n",
    "+ Derivatives/gradients of those operations known, so `autograd` package computes those derivatives\n",
    "  + (that's what `AddBackward0` object is)\n",
    "+ Invoking `y.backward()` computes value of *gradient* of `y` with respect to `x` evaluated at `x==2`:\n",
    "\n",
    "$$f'(2) = 12(2^3) - 6(2^2) + 8(2) - 1 = 96-24+16-1 = 87. $$\n",
    "\n",
    "+ Notice computed gradient value stored `x.grad` attribute of original tensor `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y.backward() # Compute derivatives and propagate values back through tensors on which y depends\n",
    "\n",
    "print(x.grad)  # Expect the value 87 as a singleton tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Notice invoking `y.backward()` a second time raises exception\n",
    "  + Intermediate arrays required for backpropagation released/deallocate by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y.backward() # Yields a RuntimeError (just like before calling backward before forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Another backpropagation example\n",
    "\n",
    "+ Use $z = \\cos(u)$ with $u=x^2$ at $x=\\sqrt{\\frac{\\pi}{3}}$\n",
    "+ Expect $z=\\frac{1}{2}$ when $x=\\sqrt{\\frac{\\pi}{3}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([np.sqrt(np.pi/3)], requires_grad=True)\n",
    "u = x ** 2\n",
    "z = torch.cos(u)\n",
    "print(f'x: {x}\\nu: {u}\\nz: {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Expect \n",
    "  $$\\frac{dz}{dx} = \\frac{dz}{du} \\frac{du}{dx} = (-\\sin u) (2 x) = \\sqrt{\\pi}$$\n",
    "  when $x=\\sqrt{\\frac{\\pi}{3}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Now apply backward for backpropagation of derivate values\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(f'x.grad:\\t\\t\\t\\t\\t\\t{x.grad}')\n",
    "x, u = x.item(), u.item() # extract scalar values\n",
    "print(f'Computed derivative using analytic formula:\\t{-np.sin(u)*2*x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "+ Notice tensors `x`, `u`, & `z` all *singleton* tensors (scalars)\n",
    "+ Method `item` extracts scalar entry from singleton tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "- [PyTorch](https://pytorch.org): Python-based scientific computing package offering:\n",
    "  - Tensor support (replacement for NumPy)\n",
    "  - Fast & flexible platform for deep learning research\n",
    "+ Supports **GPU computation**\n",
    "+ Supports **Automatic differentiation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
