{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PyTorch Convolutional NN for MNIST Classification\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson plan\n",
    "\n",
    "- Convolutional layers vs. fully-connected layers\n",
    "- Use tensorboard to inspect network training\n",
    "- Use GPU to speed-up network training (*this notebook is very slow without access to a GPU*)\n",
    "- Compute class-wise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_PATH = pathlib.Path('.') / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root=MNIST_PATH, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root=MNIST_PATH, train=False, download=True, transform=transform)\n",
    "\n",
    "print(f'Number of images in training set: {len(trainset)}')\n",
    "print(f'Number of images in test set is: {len(testset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, use_conv):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.use_conv = use_conv\n",
    "        \n",
    "        if self.use_conv:\n",
    "            self.conv1 = nn.Conv2d(1, 8, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        else:\n",
    "            self.fc0 = nn.Linear(28*28, 16*4*4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x, dbg=False):\n",
    "        if dbg: print('input: ', x.shape)\n",
    "        \n",
    "        if self.use_conv:\n",
    "            if dbg: print('start of conv. block')\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            if dbg: print(x.shape)\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            if dbg: \n",
    "                print(x.shape)\n",
    "                print('end of conv. block')\n",
    "        else:\n",
    "            if dbg: print('No conv block')\n",
    "            x = x.view(-1, 28*28)\n",
    "            x = F.relu(self.fc0(x))\n",
    "        \n",
    "        if dbg: print('start of linear block')\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        if dbg: print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if dbg: print(x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if dbg: \n",
    "            print(x.shape)\n",
    "            print('end of linear block')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_conv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(use_conv=use_conv)\n",
    "im, l = trainset[0]\n",
    "net(im.unsqueeze(0), dbg=False)\n",
    "#list(net.parameters())\n",
    "\n",
    "total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f'Total parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(use_conv=use_conv).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard for visualizing training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummerWriter()\n",
    "except:\n",
    "    writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': trainset,\n",
    "    'val': testset\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': trainloader,\n",
    "    'val': testloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_epoch = 0\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_losses = {'train': [], 'val': []}\n",
    "running_accs = {'train': [], 'val': []}\n",
    "\n",
    "for epoch in range(starting_epoch, starting_epoch+num_epochs):\n",
    "    \n",
    "    running_loss = {'train': 0.0, 'val': 0.0}\n",
    "    running_acc = {'train': 0.0, 'val': 0.0}\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "        else:\n",
    "            net.train(False)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "       \n",
    "        for batch_i, samples in enumerate(dataloaders[phase]):\n",
    "            images, labels = samples\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = net(images)\n",
    "            \n",
    "            error = criterion(outputs, labels)\n",
    "            running_loss += error.item()\n",
    "        \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_acc += (predicted == labels).sum().item()\n",
    "        \n",
    "            # check out model.eval()\n",
    "        \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                error.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        running_losses[phase].append( running_loss / len(datasets[phase]) )\n",
    "        running_accs[phase].append( running_acc * 100.0 / len(datasets[phase]) )\n",
    "    \n",
    "    if writer:\n",
    "        writer.add_scalar('Loss/train', running_losses['train'][-1], epoch)\n",
    "        writer.add_scalar('Loss/validation', running_losses['val'][-1], epoch)\n",
    "        writer.add_scalar('Accuracy/train', running_accs['train'][-1], epoch)\n",
    "        writer.add_scalar('Accuracy/validation', running_accs['val'][-1], epoch)\n",
    "    \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch={}, training err={:6.4}/acc={}, validation err={:6.4}/acc={}'.format(epoch, \n",
    "                                                                            running_losses['train'][-1], \n",
    "                                                                            running_accs['train'][-1],\n",
    "                                                                            running_losses['val'][-1],\n",
    "                                                                            running_accs['val'][-1]))\n",
    "        \n",
    "starting_epoch = epoch\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing class-specific accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        \n",
    "        for k in range(len(data)):\n",
    "            label = labels[k]\n",
    "            class_correct[label] += c[k].item()\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('Accuracy of {:5s} : {:4.1f}%'.format(\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [matplotlib's documentation on creating heatmaps](https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html), we can visualize the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (M, N).\n",
    "    row_labels\n",
    "        A list or array of length M with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length N with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[1]), labels=col_labels)\n",
    "    ax.set_yticks(np.arange(data.shape[0]), labels=row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:2d}\",\n",
    "                     textcolors=(\"black\", \"white\"),\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A pair of colors.  The first is used for values below a threshold,\n",
    "        the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "n = 0\n",
    "for inputs, labels in testloader:\n",
    "        output = net(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 9))\n",
    "\n",
    "im, cbar = heatmap(cf_matrix, np.arange(10), np.arange(10), ax=ax,\n",
    "                   cmap=\"YlGn\", cbarlabel=\"accuracy\")\n",
    "texts = annotate_heatmap(im)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "+ Using convolutions in PyTorch for image data\n",
    "+ The advantages and disadvantages of \"parameter sharing\" in neural networks\n",
    "+ Multi-class classification in PyTorch\n",
    "+ Using confusion matrices to visualize classifier performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filesystem-cybera",
   "language": "python",
   "name": "conda-env-filesystem-cybera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
