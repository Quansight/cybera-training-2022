{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PyTorch Classification with One Hidden Layer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson plan\n",
    "\n",
    "We will construct a neural network to solve a binary problem.  This neural network will consist of 1 hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pprint as pp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 120\n",
    "x, y = datasets.make_moons(n_samples=n_samples, random_state=0, noise=0.1)\n",
    "x = x - np.mean(x,0) # 0 centered\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(x[:,0], x[:,1], c=y, cmap=cm.bwr)\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data utilities\n",
    "\n",
    "Deep learning models are data intensive.  In many cases a large fraction of time is spent organizing data to support training deep neural networks.  PyTorch provides `Dataset` class in its `torch.utils.data` module to construct data loaders appropriate for deep network training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a `DataSet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'feature': torch.tensor(self.x[idx], dtype=torch.float32), \n",
    "            'label': torch.tensor(np.array([self.y[idx]]), dtype=torch.float32)}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a `DataLoader`\n",
    "\n",
    "We use dataloader class to construct batches needed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(x, y)\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "for i_batch, samples in enumerate(dataloader):\n",
    "    print('\\nbatch# = %s' % i_batch)\n",
    "    print('samples: ')\n",
    "    pp.pprint(samples)\n",
    "    break # Otherwise it prints too much stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=10):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        \n",
    "        num_classes = 2\n",
    "\n",
    "        self.hidden = nn.Linear(in_features=input_size, out_features=hidden_size, bias=True)\n",
    "        self.hidden_activation = nn.Tanh()\n",
    "        \n",
    "        self.output = nn.Linear(in_features=hidden_size, out_features=1, bias=True)\n",
    "        self.output_activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.hidden(x)\n",
    "        x2 = self.hidden_activation(x1)\n",
    "        x3 = self.output(x2)\n",
    "        x4 = self.output_activation(x3)        \n",
    "        return x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = BinaryClassification()\n",
    "print(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "\n",
    "Binary cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        log_probs = torch.where(targets.byte(), torch.log(predictions), torch.log(1.-predictions))\n",
    "        loss = - torch.sum(log_probs)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Counting how many predictions were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    ones = torch.ones(predictions.shape)\n",
    "    zeros = torch.zeros(predictions.shape)\n",
    "    \n",
    "    p = torch.where(predictions.cpu() > 0.5, ones, zeros)\n",
    "    s = torch.sum(p == targets.cpu())\n",
    "    return s.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassification().to(device)\n",
    "criterion = MyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(x, y)\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "training_sample_generator = DataLoader(dataset, \n",
    "                                       batch_size=batch_size, \n",
    "                                       shuffle=shuffle, \n",
    "                                       num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    n = 0\n",
    "    for batch_i, samples in enumerate(training_sample_generator):\n",
    "        features = samples['feature'].to(device)\n",
    "        targets = samples['label'].to(device)\n",
    "        predictions = model(features)\n",
    "        error = criterion(predictions, targets)\n",
    "        n += accuracy(predictions, targets)\n",
    "        optimizer.zero_grad()\n",
    "        error.backward()        \n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'epoch={epoch:03}. error={error.item():<7.4}. accuracy={n}')\n",
    "    \n",
    "    # If we have achieved 99% accuracy, then stop.\n",
    "    if n > .99 * n_samples: \n",
    "        break\n",
    "        \n",
    "print(f'epoch={epoch:03}. error={error.item():<7.4}. accuracy={n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Colors represent whether or not points are classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.zeros(n_samples)\n",
    "prob_of_one = model(torch.Tensor(x).to(device)).detach().cpu().numpy().flatten()\n",
    "predicted_labels[prob_of_one > 0.5] = 1\n",
    "\n",
    "# Color 1 represent correct classification, 0 otherwise\n",
    "colors = np.where(predicted_labels == y, 1, 0) \n",
    "\n",
    "accuracy = np.sum(colors)\n",
    "print(f'accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Classification results')\n",
    "plt.scatter(x[:,0], x[:,1], c=colors, cmap=cm.bwr)\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcoord = np.linspace(-3, 3)\n",
    "ycoord = np.linspace(-3, 3)\n",
    "xx, yy = np.meshgrid(xcoord, ycoord)\n",
    "xxt = torch.tensor(xx, dtype=torch.float32).view(-1).unsqueeze(0)\n",
    "yyt = torch.tensor(yy, dtype=torch.float32).view(-1).unsqueeze(0)\n",
    "# print(xxt.shape)\n",
    "# print(yyt.shape)\n",
    "v = torch.t(torch.cat([xxt,yyt]))\n",
    "# print(v.shape)\n",
    "m = model(v.to(device))\n",
    "# print(m.shape)\n",
    "mm = m.detach().cpu().numpy().reshape(50,50)\n",
    "# print(mm.shape)\n",
    "\n",
    "x_try = torch.tensor(x, dtype=torch.float32)\n",
    "y_try = model(x_try.to(device))\n",
    "yy_try = (y_try.squeeze() > 0.5).cpu().numpy()\n",
    "# print(yy_try)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "extent = -3, 3, -3, 3\n",
    "plt.imshow(mm, cmap=cm.BuGn, interpolation='bilinear', extent=extent, alpha=.5, origin='lower')\n",
    "plt.scatter(x[:,0], x[:,1], c=yy_try, cmap=cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)\n",
    "plt.title('Classification results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filesystem-cybera",
   "language": "python",
   "name": "conda-env-filesystem-cybera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
