{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Outline\n",
    "\n",
    "- Where's Waldo?\n",
    "- Techniques for comparing patches\n",
    "- Scale considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Where's Waldo?\n",
    "\n",
    "Our task is to find Waldo\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/waldo.png\" width=\"15%\"></img></td>\n",
    "    </tr>\n",
    "</center>\n",
    "\n",
    "in the crowd\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/where-is-waldo.jpg\" width=\"95%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Key insight\n",
    "\n",
    "**Compare** patches in the image with Waldo's picture.  In order to do so, we need to be able determine if patch 1 is more similar to patch 2 or patch 3 (as shown in the figure below).\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/patch-similarity.png\" width=\"65%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Template Matching\n",
    "\n",
    "Given a source image $I$ and a template $T$, we compare the template image against the source image by sliding it one pixel at a time (left to right, top to bottom) and computing a similarity (or alternately difference) between template and the image patch at each location.  The similarity scores is computed using a suitable function $g(T, I, i, j) \\mapsto R(i,j)$, where $R(i,j)$ is the similarity score for between the template and the image patch at location $(i,j)$.  Location corresponding to highest (or alternately lowest) value in the result matrix $R$ representing the \"match location.\"\n",
    "\n",
    "A common trick is to treat both the template and patches as vectors in a high-dimensional space.  The template-patch-matching problem is then reduced to finding the nearest vector (in this high-dimensional space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Picking image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I = cv.imread('data/where-is-waldo.jpg')\n",
    "I = cv.cvtColor(I, cv.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Let's pick a patch from this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y, x = 1000, 750\n",
    "half_h, half_w = 100, 200\n",
    "\n",
    "def pick_patch(I, y, x, half_h, half_w):\n",
    "    return I[y-half_h:y+half_h+1, x-half_w:x+half_w+1, :]\n",
    "\n",
    "# Loop to extract 3 vertically shifted patches\n",
    "for yi in range(3):\n",
    "    for xi in range(1):\n",
    "        x_ = x + 30 * xi\n",
    "        y_ = y + 30 * yi\n",
    "        patch = pick_patch(I, y_, x_, half_h, half_w)\n",
    "        fig = plt.figure(figsize=(5,5))\n",
    "        plt.imshow(patch)\n",
    "        plt.title('Patch: yx = {}, size = {}'.format((y_,x_), patch.shape[:2]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "template = cv.imread('data/waldo.png')\n",
    "template = cv.cvtColor(template, cv.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(template);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Flatten template & patch into vectors\n",
    "template = template.flatten()\n",
    "patch = pick_patch(I, 300, 400, 15, 15).flatten()\n",
    "print('Template size = {}'.format(template.shape[0]))\n",
    "print('Patch size = {}'.format(patch.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Herein lies the problem.  How do we compare two vectors of different sizes?  \n",
    "\n",
    "**Observation 1**: The template and the patch must have the same dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Techniques for comparing patches\n",
    "\n",
    "We now discuss methods for comparing image patches (and templates):\n",
    "\n",
    "- Sum of squared differences\n",
    "- Normalized sum of squared differences\n",
    "- Cross-correlation\n",
    "- Normalized cross-correlation\n",
    "- Correlation coefficient\n",
    "- Normalized correlation coefficient\n",
    "\n",
    "The following discussion assumes that patches (and templates) have the same dimensions (*observation 1 above*).  We also use the following notation:\n",
    "\n",
    "- Template: $T$\n",
    "- Image: $I$\n",
    "- Image patch centered at $(i,j)$: $I(i+k, j+l)$\n",
    "- Response: $R$\n",
    "\n",
    "*Aside*:\n",
    "\n",
    "For OpenCV Template Matching function if image is $W \\times H$ and template is $w \\times h$ then result $R$ is $(W-w+1) \\times (H-h+1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Image\n",
    "img_waldo = cv.imread('data/where-is-waldo.jpg')\n",
    "img_waldo = cv.cvtColor(img_waldo, cv.COLOR_BGR2RGB)\n",
    "img_waldo_zoomed = img_waldo[344:824, 1100:1440, :]\n",
    "img = cv.cvtColor(img_waldo_zoomed, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "# Template\n",
    "waldo = img_waldo_zoomed[167:264,123:179,:]\n",
    "template = cv.cvtColor(waldo, cv.COLOR_RGB2GRAY)\n",
    "overlaid = np.ones(img_waldo_zoomed.shape, dtype=img_waldo_zoomed.dtype)*255\n",
    "overlaid[0:waldo.shape[0],0:waldo.shape[1],:] = waldo\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Cropped image')\n",
    "plt.imshow(img_waldo_zoomed)\n",
    "plt.subplot(132)\n",
    "plt.title('Template')\n",
    "plt.imshow(waldo)\n",
    "plt.subplot(133)\n",
    "plt.title('Template (Actual Size)')\n",
    "plt.imshow(overlaid)\n",
    "plt.suptitle('Image and template used for the following examples');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Sum of Squared Differences (SSD)\n",
    "\n",
    "$$\n",
    "R(i,j) = \\sum_{k,l} \\left( I(i+k, j+l) - T(k,l)  \\right)^2\n",
    "$$\n",
    "\n",
    "Here $R(i,j)$ encodes the distance between the template and image patch centered at image location $(i,j)$.  The smaller this value, the more similar is template to the patch.\n",
    "\n",
    "SSD is sensitive to average intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "T = template.copy()\n",
    "I = img.copy()\n",
    "\n",
    "method = 'cv2.TM_SQDIFF'\n",
    "R = cv.matchTemplate(I, T, eval(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "R.shape, T.shape, I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def highlight(R, T, I, use_max=True):\n",
    "    \"\"\"Given Response matrix R, Template T, and Image I\"\"\"\n",
    "    W, H = I.shape[0], I.shape[1]\n",
    "    w, h = T.shape[0], T.shape[1]\n",
    "    wr, hg = R.shape[0], R.shape[1]\n",
    "        \n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(R)\n",
    "    # Distinguishes maximizer of R from minimizer of R\n",
    "    loc = max_loc if use_max else min_loc\n",
    "    loc = loc + np.array([h//2, w//2])               # Size of R is different from I \n",
    "    tl = loc - np.array([h//2, w//2])\n",
    "    br = loc + np.array([h//2, w//2])\n",
    "    I_ = np.copy(I)\n",
    "    c = (1.0, 0, 0) if I_.dtype == 'float32' else (255, 0, 0)\n",
    "    cv.rectangle(I_, tuple(tl), tuple(br), c, 4)\n",
    "    return I_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "I_ = highlight(R, T, img_waldo_zoomed, use_max=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Response $R(i,j)$')\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_)\n",
    "plt.suptitle(method)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Sum of Squared Differences Normalized (SSD)\n",
    "\n",
    "$$\n",
    "R(i,j) = \n",
    "\\frac{\\sum_{k,l} \\left( I(i+k, j+l) - T(k,l)  \\right)^2}\n",
    "{\\sqrt{\\sum_{k,l} I(i+k, j+l)^2 \\sum_{k,l} T(k,l)^2}}\n",
    "$$\n",
    "\n",
    "The smaller this value, the more similar is template to the patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Repeat above with different normalized SSD for comparison\n",
    "T = template.copy()\n",
    "I = img.copy()\n",
    "\n",
    "method = 'cv2.TM_SQDIFF_NORMED'\n",
    "R = cv.matchTemplate(I, T, eval(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "I_ = highlight(R, T, img_waldo_zoomed, use_max=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Response $R(i,j)$')\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_)\n",
    "plt.suptitle(method)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Cross-Correlation\n",
    "\n",
    "$$\n",
    "R(i,j) = \\sum_{k,l} I(i+k, j+l)  T(k, l)\n",
    "$$\n",
    "\n",
    "Response is stronger for higher intensities, which leads to *false positive*.  Recall that cross-correlation can be implemented as *linear filtering*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Repeat above using cross-correlation instead\n",
    "T = template.copy()\n",
    "I = img.copy()\n",
    "\n",
    "method = 'cv2.TM_CCORR'\n",
    "R = cv.matchTemplate(I, T, eval(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "I_ = highlight(R, T, img_waldo_zoomed, use_max=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Response $R(i,j)$')\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.title('False positive here!')\n",
    "plt.imshow(I_)\n",
    "plt.suptitle(method)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Normalized Cross Correlation\n",
    "\n",
    "$$\n",
    "R(i,j) = \n",
    "\\frac{\\sum_{k,l} I(i+k, j+l)  T(k, l)}\n",
    "{\\sqrt{\\sum_{k,l} I(i+k, j+l)^2 \\sum_{k,l} T(k, l)^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "T = template.copy()\n",
    "I = img.copy()\n",
    "\n",
    "method = 'cv2.TM_CCORR_NORMED'\n",
    "R = cv.matchTemplate(I, T, eval(method))\n",
    "I_ = highlight(R, T, img_waldo_zoomed, use_max=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Response $R(i,j)$')\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_)\n",
    "plt.suptitle(method)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Correlation Coefficient\n",
    "\n",
    "$$\n",
    "R(i,j) = \\sum_{k,l} I'(i+k, j+l) T'(k, l)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "I' &= I - \\frac{1}{wh} \\sum_{k',l'} I(i+k',j+l') \\\\\n",
    "T' &= T - \\frac{1}{wh} \\sum_{k',l'} T(k',l')\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$w$ and $h$ refer to the width and height of template $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "T = template.copy()\n",
    "I = img.copy()\n",
    "\n",
    "method = 'cv2.TM_CCOEFF'\n",
    "R = cv.matchTemplate(I, T, eval(method))\n",
    "I_ = highlight(R, T, img_waldo_zoomed, use_max=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Response $R(i,j)$')\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_)\n",
    "plt.suptitle(method)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### Correlation Coefficient Definition\n",
    "\n",
    "A measure of the degree to which the movement of two random variables are associated\n",
    "\n",
    "$$\n",
    "\\rho_{xy} = \\frac{\\mathrm{cov}(x,y)}{\\sigma_x \\sigma_y}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$\\mathrm{cov}(x,y) = \\mathrm{E}[(x - \\mu_x)(y - \\mu_x)] $ is covariance of random variables $x$ and $y$, and $\\mu_x$, $\\mu_y$, $\\sigma_x$ and $\\sigma_y$ are, respectively, their means and standard deviations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Correlation Coefficient Normalized\n",
    "\n",
    "$$\n",
    "R(i,j) = \n",
    "\\frac{\\sum_{k,l} I'(i+k, j+l) T'(k, l)}\n",
    "{\\sqrt{\\sum_{k,l}I'(i+k, j+l)^2 \\sum_{k,l} T'(k,l)^2}}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "I' &= I - \\frac{1}{wh} \\sum_{k',l'} I(i+k',j+l') \\\\\n",
    "T' &= T - \\frac{1}{wh} \\sum_{k',l'} T(k',l')\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$w$ and $h$ refer to the width and height of template $T$.\n",
    "\n",
    "Invariant to mean and scale of intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "T = template.copy()\n",
    "I = img.copy()\n",
    "\n",
    "method = 'cv2.TM_CCOEFF_NORMED'\n",
    "R = cv.matchTemplate(I, T, eval(method))\n",
    "I_ = highlight(R, T, img_waldo_zoomed, use_max=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Response $R(i,j)$')\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_)\n",
    "plt.suptitle(method)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Scale considerations\n",
    "\n",
    "Thus far, we have assumed that template is the same size (i.e., similar scale) as the target object in the image.  Notice the \"Waldo\" template has the same size (i.e., height and width) as the size of \"Waldo\" seen in the image.  What happens if this assumption is untrue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Image\n",
    "scale = 4\n",
    "img_waldo = cv.imread('data/where-is-waldo.jpg')\n",
    "img_waldo = cv.cvtColor(img_waldo, cv.COLOR_BGR2RGB)\n",
    "img_waldo_zoomed = img_waldo[344:824, 1100:1440, :]\n",
    "H, W = img_waldo_zoomed.shape[0], img_waldo_zoomed.shape[1]\n",
    "img_waldo_resized = cv.resize(img_waldo_zoomed, (int(W*scale),int(H*scale)))\n",
    "img = cv.cvtColor(img_waldo_resized, cv.COLOR_RGB2GRAY)\n",
    "print(f'Original image size: {img_waldo.shape}')\n",
    "print(f'Original cropped image size: {img_waldo_zoomed.shape}')\n",
    "print(f'Scaled, cropped image size: {img_waldo_resized.shape}')\n",
    "\n",
    "# Template\n",
    "waldo = img_waldo_zoomed[167:264,123:179,:]\n",
    "template = cv.cvtColor(waldo, cv.COLOR_RGB2GRAY)\n",
    "overlaid = np.ones(img_waldo_resized.shape, dtype=img_waldo_resized.dtype)*255\n",
    "overlaid[0:waldo.shape[0],0:waldo.shape[1],:] = waldo\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Image')\n",
    "plt.imshow(img_waldo_resized)\n",
    "plt.subplot(132)\n",
    "plt.title('Template')\n",
    "plt.imshow(waldo)\n",
    "plt.subplot(133)\n",
    "plt.title('Template (Actual Size)')\n",
    "plt.imshow(overlaid)\n",
    "plt.suptitle('Image and template used for the following examples');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform template matching to find waldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "T = template.copy()\n",
    "I = img.copy()\n",
    "\n",
    "methods = ['cv2.TM_CCOEFF', \n",
    "           'cv2.TM_CCOEFF_NORMED', \n",
    "           'cv2.TM_CCORR',\n",
    "           'cv2.TM_CCORR_NORMED', \n",
    "           'cv2.TM_SQDIFF', \n",
    "           'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "method = methods[4]\n",
    "R = cv.matchTemplate(I, T, eval(method))\n",
    "I_ = highlight(R, T, img_waldo_resized, use_max=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Response $R(i,j)$')\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_)\n",
    "plt.suptitle(method)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "**Observation 2**: Template matching is not scale invariant.  \n",
    "\n",
    "We need to perform scale space analysis for template matching.  In other words, we need to use image pyramids: construct an image pyramid, perform template matching at each scale, find the correct scale and location within that scale using maxima (minima) search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Other Considerations\n",
    "\n",
    "Is template matching rotation invariant?  What about occlusions?  What about shifts in color? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Based on materials from Prof. Faisal Qureshi (Faculty of Science, Ontario Tech University, Oshawa ON, Canada, http://vclab.science.ontariotechu.ca)\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
