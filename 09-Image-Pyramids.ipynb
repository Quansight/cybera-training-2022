{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- Gaussian image pyramids\n",
    "- Laplacian image pyramids\n",
    "- Laplacian blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Image Pyramid\n",
    "\n",
    "The basic idea for constructing Gaussian image pyramid is as follows:\n",
    "\n",
    "1. Gaussian blur the image\n",
    "2. Reduce image dimensions by half by discarding every other row and and every other column\n",
    "3. Repeat this process until desired numbers levels are achieved or the image is reduced to size $1 \\times 1$.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/zebra-gaussian-pyramid.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Courtesy D. Forsyth</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image pyramids often used for scale-invariant image processing:\n",
    "\n",
    "- template matching;\n",
    "- image registration;\n",
    "- image enhancement;\n",
    "- interest point detection; and\n",
    "- object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercise: construct 2-level Gaussian pyramid in Python\n",
    "\n",
    "- Load image `data/apple.jpg`\n",
    "- Blur each channel with a 5-by-5 Gaussian kernel\n",
    "- Construct the next level of Gaussian pyramid by discarding every other row or column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/04/solution_01.py\n",
    "I = cv.imread('data/apple.jpg')\n",
    "I = cv.cvtColor(I, cv.COLOR_BGR2RGB)\n",
    "\n",
    "print('Shape of I = {}'.format(I.shape))\n",
    "I[:,:,0] = cv.GaussianBlur(I[:,:,0], (5,5), 2, 2)\n",
    "I[:,:,1] = cv.GaussianBlur(I[:,:,1], (5,5), 2, 2)\n",
    "I[:,:,2] = cv.GaussianBlur(I[:,:,2], (5,5), 2, 2)\n",
    "\n",
    "I2 = I[::2,::2,:]\n",
    "print('Shape of I2 = {}'.format(I2.shape))\n",
    "\n",
    "plt.imshow(I2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation (Gaussian Image Pyramid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV function `pyrDown` method automates the steps above: blurring with a Gaussian filter & downsampling.  It uses the following kernel to blur the image (in step 1):\n",
    "\n",
    "$$\n",
    "\\frac{1}{256}\n",
    "\\left[\n",
    "\\begin{array}{ccccc}\n",
    "1 & 4 & 6 & 4 & 1 \\\\\n",
    "4 & 16 & 24 & 16 & 4 \\\\\n",
    "6 & 24 & 36 & 24 & 6 \\\\\n",
    "4 & 16 & 24 & 16 & 4 \\\\\n",
    "1 & 4 & 6 & 4 & 1\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/04/gen_gaussian_pyramid.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 2 images to decompose into Gaussian pyramids\n",
    "A = cv.imread('data/apple.jpg')\n",
    "B = cv.imread('data/orange.jpg')\n",
    "A = cv.cvtColor(A, cv.COLOR_BGR2RGB)\n",
    "B = cv.cvtColor(B, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpA = gen_gaussian_pyramid(A)\n",
    "gpB = gen_gaussian_pyramid(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = gpB\n",
    "num_levels = len(gp)\n",
    "for i in range(num_levels):\n",
    "    rows = gp[i].shape[0]\n",
    "    cols = gp[i].shape[1]\n",
    "    print('level={}: size={}x{}'.format(i, rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = gpA\n",
    "level = 3\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Level {}'.format(level))\n",
    "plt.imshow(gp[level]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian Image Pyramid\n",
    "\n",
    "Proposed by Burt and Adelson is a bandpass image decomposition derived from the Gaussian pyramid.  Each level encodes information at a particular spatial frequency.  The basic steps for constructing Laplacian pyramids are:\n",
    "\n",
    "1. Convolve the original image $g_0$ with a lowpass filter $w$ (e.g., the Gaussian filter) and subsample it by two to create a reduced lowpass version of the image $g_1$.  Recall that this is what function `pyrDown` does.\n",
    "\n",
    "2. Upsample this image (i.e., $g_1$) by inserting zeros in between each row and column and interpolating the missing values by convolving it with the same filter $w$ to create the expanded lowpass image $g'_1$ which is subtracted pixel by pixel from the original to give the detail image $L_0$.  Specifically $L_0 = g_0 - g'_1$.\n",
    "3. Repeat steps 1 and 2.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/zebra-laplacian-pyramid.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Courtesy D. Forsyth</figcaption>\n",
    "</figure>\n",
    "\n",
    "We define Laplacian operator as follows:\n",
    "\n",
    "$$\n",
    "\\nabla^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}\n",
    "$$\n",
    "\n",
    "In addition we can approximate the Laplacian of a Gaussian as follows:\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right: auto; text-align: center; display: block; max-width: 700px;\">\n",
    "<img src=\"images/laplacian-of-a-gaussian.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<figcaption style=\"text-align: center; margin-bottom: 10px; font-style: italic;\">Source: Lazebnik</figcaption>\n",
    "</figure>\n",
    "\n",
    "We use this property when constructing Laplacian image pyramids above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing the original image\n",
    "\n",
    "It is possible to reconstruct the original image $g_0$ from its Laplacian image pyramd consisting of $N+1$ detail images $L_i$, where $i \\in [0,N]$ and the low pass image $g_N$.\n",
    "\n",
    "1. $g_N$ is upsampled by inserting zeros between the sample values and interpolating the missing values by convolving it with the filter $w$ to obtain the image $g'_N$.\n",
    "2. The image $g'_N$ is added to the lowest level detail image $L_N$ to obtain the approximation image at the next upper level.\n",
    "3. Steps 1 and 2 are repeated on the detail images $L_i$ to obtain the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses\n",
    "\n",
    "Laplacian image pyramids are often used for compression.  Instead of encoding $g_0$, we encode $L_i$, which are decorrelated and can be represented using far fewer bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation (Laplacian Image Pyramid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/04/gen_laplacian_pyramid.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpA = gen_laplacian_pyramid(gpA)\n",
    "lpB = gen_laplacian_pyramid(gpB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = lpA\n",
    "num_levels = len(lp)\n",
    "for i in range(num_levels):\n",
    "    rows = lp[i].shape[0]\n",
    "    cols = lp[i].shape[1]\n",
    "    print('level={}: size={}x{}'.format(i, cols, rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Blending Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = lpA\n",
    "level = 3\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Level {}'.format(level))\n",
    "plt.imshow(lp[level]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/04/laplacian_blending.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/04/reconstruct_from_laplacian.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = np.hstack((A[:,:cols//2],B[:,cols//2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(ls_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(real);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Summary\n",
    "\n",
    "- Gaussian pyramid\n",
    "    - Coarse-to-fine search\n",
    "    - Multi-scale image analysis (*hold this thought*)\n",
    "- Laplacian pyramid\n",
    "    - More compact image representation\n",
    "    - Can be used for image compositing (computation photography)\n",
    "- Downsampling\n",
    "    - *Nyquist limit*:  The Nyquist limit gives us a theoretical limit to what rate we have to sample a signal that contains data at a certain maximum frequency. Once we sample below that limit, not only can we not accurately sample the signal, but the data we get out has corrupting artifacts. These artifacts are \"aliases\".\n",
    "    - Need to sufficiently low-pass before downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various image representations\n",
    "\n",
    "- Pixels: great for spatial processing, poor access to frequency\n",
    "- Fourier transform: great for frequency analysis, poor spatial info\n",
    "- Pyramids: trade-off between spatial and frequency information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Based on materials from Prof. Faisal Qureshi (Faculty of Science, Ontario Tech University, Oshawa ON, Canada, http://vclab.science.ontariotechu.ca)\n",
    "\n",
    "<center>\n",
    "    <tr>\n",
    "    <td><img src=\"images/Quansight_Logo_Lockup_1.png\" width=\"25%\"></img></td>\n",
    "    </tr>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
